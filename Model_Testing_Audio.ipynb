{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, RNN, Layer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import time\n",
        "\n",
        "# tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clipped_relu(x):\n",
        "\n",
        "    return tf.keras.activations.relu(x, max_value=20.0)\n",
        "\n",
        "def clipped_sigmoid(x):\n",
        "\n",
        "    return tf.keras.activations.sigmoid(x) * 10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "@keras.utils.register_keras_serializable(package=\"Custom\", name=\"LTCCell\")\n",
        "class LTCCell(Layer):\n",
        "\n",
        "    def __init__(self, units, ode_unfolds=6, l2_reg=0.001, **kwargs):\n",
        "\n",
        "        super(LTCCell, self).__init__(**kwargs)\n",
        "\n",
        "        self.units = units\n",
        "\n",
        "        self.ode_unfolds = ode_unfolds\n",
        "\n",
        "        self.state_size = units\n",
        "\n",
        "        self.l2_reg = l2_reg  # L2 regularization parameter\n",
        "\n",
        "\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.input_dim = input_shape[-1]\n",
        "\n",
        "        # Trainable parameters with L2 regularization\n",
        "\n",
        "        self.W = self.add_weight(\n",
        "\n",
        "            shape=(self.input_dim + self.units, self.units),\n",
        "\n",
        "            initializer='glorot_uniform',\n",
        "\n",
        "            regularizer=l2(self.l2_reg),\n",
        "\n",
        "            name='W'\n",
        "\n",
        "        )\n",
        "\n",
        "        self.bias = self.add_weight(\n",
        "\n",
        "            shape=(self.units,),\n",
        "\n",
        "            initializer='zeros',\n",
        "\n",
        "            name='bias'\n",
        "\n",
        "        )\n",
        "\n",
        "        self.tau = self.add_weight(\n",
        "\n",
        "            shape=(self.units,),\n",
        "\n",
        "            initializer='ones',\n",
        "\n",
        "            name='tau'\n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "        self.C = self.add_weight(\n",
        "\n",
        "            shape=(self.units,),\n",
        "\n",
        "            initializer='ones',\n",
        "\n",
        "            name='C'\n",
        "\n",
        "        )\n",
        "\n",
        "        self.G = self.add_weight(\n",
        "\n",
        "            shape=(self.units,),\n",
        "\n",
        "            initializer='ones',\n",
        "\n",
        "            name='G'\n",
        "\n",
        "        )\n",
        "\n",
        "        super(LTCCell, self).build(input_shape)\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "\n",
        "        prev_state = states[0]\n",
        "\n",
        "        concatenated = tf.concat([inputs, prev_state], axis=1)\n",
        "\n",
        "        dt = 0.01  # Time step\n",
        "\n",
        "\n",
        "\n",
        "        for _ in range(self.ode_unfolds):\n",
        "\n",
        "            dh = (-prev_state + tf.nn.tanh(tf.matmul(concatenated, self.W) + self.bias)) / tf.nn.softplus(self.tau)\n",
        "\n",
        "            prev_state += dt * dh\n",
        "\n",
        "\n",
        "\n",
        "        # Apply custom activation functions\n",
        "\n",
        "        prev_state = clipped_relu(prev_state)\n",
        "\n",
        "        prev_state = prev_state * clipped_sigmoid(self.C)\n",
        "\n",
        "        prev_state = prev_state / clipped_sigmoid(self.G)\n",
        "\n",
        "\n",
        "\n",
        "        return prev_state, [prev_state]\n",
        "    \n",
        "    def get_config(self):\n",
        "        \n",
        "        config = super(LTCCell, self).get_config()\n",
        "        \n",
        "        config.update({\"units\": self.units})\n",
        "        \n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing segment 1...\n",
            "Detected Emotion: neutral\n",
            "Latency: 0.4017 seconds\n",
            "Processing segment 2...\n",
            "Detected Emotion: neutral\n",
            "Latency: 0.1544 seconds\n",
            "Processing segment 3...\n",
            "Detected Emotion: angry\n",
            "Latency: 0.1471 seconds\n",
            "Processing segment 4...\n",
            "Detected Emotion: neutral\n",
            "Latency: 0.1434 seconds\n",
            "Processing segment 5...\n",
            "Detected Emotion: angry\n",
            "Latency: 0.1526 seconds\n",
            "Processing segment 6...\n",
            "Detected Emotion: angry\n",
            "Latency: 0.1450 seconds\n",
            "Processing segment 7...\n",
            "Detected Emotion: angry\n",
            "Latency: 0.1621 seconds\n",
            "Processing segment 8...\n",
            "Detected Emotion: sad\n",
            "Latency: 0.1679 seconds\n",
            "Processing segment 9...\n",
            "Detected Emotion: angry\n",
            "Latency: 0.1416 seconds\n",
            "Processing segment 10...\n",
            "Detected Emotion: angry\n",
            "Latency: 0.1451 seconds\n",
            "Processing segment 11...\n",
            "Detected Emotion: sad\n",
            "Latency: 0.1469 seconds\n",
            "Processing segment 12...\n",
            "Detected Emotion: sad\n",
            "Latency: 0.1505 seconds\n",
            "Processing segment 13...\n",
            "Detected Emotion: angry\n",
            "Latency: 0.1536 seconds\n",
            "Processing segment 14...\n",
            "Detected Emotion: angry\n",
            "Latency: 0.1456 seconds\n",
            "Processing segment 15...\n",
            "Detected Emotion: angry\n",
            "Latency: 0.1600 seconds\n",
            "Processing segment 16...\n",
            "Detected Emotion: angry\n",
            "Latency: 0.1442 seconds\n",
            "Processing segment 17...\n",
            "Detected Emotion: neutral\n",
            "Latency: 0.1504 seconds\n",
            "Processing segment 18...\n",
            "Detected Emotion: neutral\n",
            "Latency: 0.1486 seconds\n",
            "Processing segment 19...\n",
            "Detected Emotion: angry\n",
            "Latency: 0.1498 seconds\n",
            "Processing segment 20...\n",
            "Detected Emotion: angry\n",
            "Latency: 0.1423 seconds\n",
            "Processing segment 21...\n",
            "Detected Emotion: angry\n",
            "Latency: 0.1546 seconds\n",
            "Processing segment 22...\n",
            "Detected Emotion: neutral\n",
            "Latency: 0.1426 seconds\n",
            "Processing segment 23...\n",
            "Detected Emotion: neutral\n",
            "Latency: 0.1436 seconds\n",
            "Processing segment 24...\n",
            "Detected Emotion: sad\n",
            "Latency: 0.1646 seconds\n",
            "Processing segment 25...\n",
            "Detected Emotion: angry\n",
            "Latency: 0.1546 seconds\n",
            "Processing segment 26...\n",
            "Detected Emotion: angry\n",
            "Latency: 0.1516 seconds\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load your model\n",
        "model = keras.models.load_model('emotion_model_63.h5', custom_objects={\"LTCCell\": LTCCell})\n",
        "\n",
        "# Preprocessing function\n",
        "def extract_features_from_audio(audio, sample_rate):\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13)\n",
        "    mfcc_delta = librosa.feature.delta(mfcc)\n",
        "    mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
        "    features = np.concatenate((mfcc, mfcc_delta, mfcc_delta2), axis=0)\n",
        "    features = features.T  # Shape: (time_steps, features)\n",
        "\n",
        "    # Expected shape for the model\n",
        "    expected_time_steps = 911\n",
        "    expected_features = 39\n",
        "\n",
        "    # Check if the number of time steps matches the expected shape\n",
        "    if features.shape[0] < expected_time_steps:\n",
        "        # Pad with zeros\n",
        "        pad_width = ((0, expected_time_steps - features.shape[0]), (0, 0))  # Correct format\n",
        "        features = np.pad(features, pad_width, mode='constant')\n",
        "    else:\n",
        "        # Truncate\n",
        "        features = features[:expected_time_steps, :]\n",
        "\n",
        "    return features\n",
        "\n",
        "# Function to process an audio file\n",
        "def process_audio_file(file_path):\n",
        "    # Load the audio file\n",
        "    audio, sample_rate = librosa.load(file_path, sr=16000)  # Resample to 16kHz if necessary\n",
        "\n",
        "    # Split the audio into 2-second segments\n",
        "    segment_length = 2 * sample_rate\n",
        "    segments = [audio[i:i + segment_length] for i in range(0, len(audio) - segment_length + 1, segment_length)]\n",
        "\n",
        "    # Process each segment\n",
        "    for i, segment in enumerate(segments):\n",
        "        print(f\"Processing segment {i + 1}...\")\n",
        "\n",
        "        # Start timer for latency measurement\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Extract features from the segment\n",
        "        features = extract_features_from_audio(segment, sample_rate)\n",
        "\n",
        "        # Reshape features to match the model's input shape\n",
        "        features = np.expand_dims(features, axis=0)  # Add batch dimension\n",
        "\n",
        "        # Predict emotion\n",
        "        prediction = model.predict(features, verbose=0)\n",
        "        emotion_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "        # Map index to emotion label\n",
        "        emotion_labels = [\"angry\", \"happy\", \"sad\", \"neutral\"] \n",
        "        detected_emotion = emotion_labels[emotion_index]\n",
        "\n",
        "        # End timer for latency measurement\n",
        "        end_time = time.time()\n",
        "        latency = end_time - start_time\n",
        "\n",
        "        # Display result and latency\n",
        "        print(f\"Detected Emotion: {detected_emotion}\")\n",
        "        print(f\"Latency: {latency:.4f} seconds\")\n",
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    # Path to the audio file\n",
        "    audio_file_path = \"angry-2.mp3\"  # Replace with your audio file path\n",
        "\n",
        "    # Process the audio file\n",
        "    process_audio_file(audio_file_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
